# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OMnKeNAE0xdyyyzX6vtOwmB6a77JTJFx
"""



import requests, datetime
import pandas as pd
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit, current_timestamp
from pyspark.sql.types import FloatType

# Initialize Spark session
spark = SparkSession.builder \
    .appName("ETL_Assessment_UsamaZaid") \
    .config("spark.jars", "/content/sample_data/mysql-connector-j-9.3.0.jar") \
    .getOrCreate()

# Load input CSV files
sales_df = spark.read.csv("/content/sample_data/sales_data.csv", header=True, inferSchema=True)
product_df = spark.read.csv("/content/sample_data/product_reference.csv", header=True, inferSchema=True)

# Step 1: Data cleaning
clean_df = sales_df.dropDuplicates().na.drop(subset=["SaleAmount", "ProductID", "Currency"])

# Step 2: Reference lookup validation
validated_df = clean_df.join(product_df, on="ProductID", how="inner")

# Step 3: Currency conversion via API
def fetch_rates():
    try:
        res = requests.get("https://api.exchangerate-api.com/v4/latest/EUR", timeout=5)
        data = res.json()
        print("API response received successfully")
        return data.get("rates", {})
    except Exception as e:
        print("API request failed:", str(e))
        print("Using fallback exchange rates")
        return {"USD": 1.16, "GBP": 0.867, "EUR": 1.0}

rates = fetch_rates()
rate_source = "Live" if rates.get("USD", 1.16) != 1.16 else "Fallback"

def convert_to_usd(sale_amount, currency):
    try:
        rate = rates.get(currency)
        usd_rate = rates.get("USD", 1.0)
        if rate:
            return float(sale_amount) / rate * usd_rate
        else:
            return None
    except:
        return None

convert_udf = spark.udf.register("convert_to_usd", convert_to_usd, FloatType())

converted_df = validated_df.withColumn("SaleAmount_USD", convert_udf(col("SaleAmount"), col("Currency")))

# Step 4: Conversion logging
log_df = converted_df.select(
    col("OrderID").alias("RecordID"),
    col("Currency").alias("OriginalCurrency"),
    col("SaleAmount_USD"),
    current_timestamp().alias("ConversionTimestamp"),
    lit(rates.get("USD", 1.16)).alias("ConversionRate"),
    lit(rate_source).alias("RateSource")
)

# Step 5: Error handling and monitoring
error_df = converted_df.filter(col("SaleAmount_USD").isNull())
clean_final_df = converted_df.filter(col("SaleAmount_USD").isNotNull())

error_rate = error_df.count() / converted_df.count()
if error_rate > 0.05:
    raise Exception("Pipeline aborted: more than 5% of records failed conversion")

# Step 6: Write results to MySQL tables
jdbc_url = "jdbc:mysql://sql12.freesqldatabase.com:3306/sql12791174"
connection_props = {
    "user": "sql12791174",
    "password": "ehfTsN1yXX",
    "driver": "com.mysql.cj.jdbc.Driver"
}

try:
    clean_final_df.write.jdbc(
        url=jdbc_url,
        table="final_cleaned_sales",
        mode="overwrite",
        properties=connection_props
    )
    log_df.write.jdbc(
        url=jdbc_url,
        table="conversion_log",
        mode="overwrite",
        properties=connection_props
    )
    error_df.write.jdbc(
        url=jdbc_url,
        table="rejected_records",
        mode="overwrite",
        properties=connection_props
    )
    print("All tables written successfully to MySQL.")
except Exception as e:
    print("Database write failed:", str(e))